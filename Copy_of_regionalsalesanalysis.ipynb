{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUD9g4u8pAVloY+ChF4lDf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizmtetwa/Data-Analytics-Portfolio-/blob/main/Copy_of_regionalsalesanalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regional Sales Analysis **\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "This project analyses sales data across different regions to uncover trends, compare perfomance and generate actionable business insights.\n",
        "\n",
        "The main objectives are:-\n",
        "\n",
        "\n",
        "*   to identify top-perfoming regions and underperforming regions.\n",
        "\n",
        "\n",
        "*   to visualise sales trends over time and across product categories.\n",
        "\n",
        "\n",
        "*   to provide recommendations for improving sales and regional strategies\n",
        " The dataset includes information on sales product categories, regions and other relevantant metrics.  By exploring and visualising this data we aim to help decision-makers optimise sales strategies and focus resources effectively.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XkG1Ph084TW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "#upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "#get the file name (the first iploaded file)\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "#load the dataset into a dataframe\n",
        "if file_name.endswith('csv'):\n",
        "  df=pd.read_csv(file_name)\n",
        "elif file_name.endswith('.xlsx'):\n",
        "  df = pd.read_excel(file_name)\n",
        "else:\n",
        "  print('unsupported file type')\n",
        "\n",
        "  #show first 5 rows\n",
        "  display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "WSYMoGU18KjH",
        "outputId": "ba465f90-de24-4072-f109-ea06061ffa92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-799f27e5-0c90-473a-aa95-5ffe3dfde1ec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-799f27e5-0c90-473a-aa95-5ffe3dfde1ec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-808782786.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#upload file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#get the file name (the first iploaded file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbf02542"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92aff09d"
      },
      "source": [
        "**Displaying Summary statistics**:\n",
        "Calculate and display summary statistics for all numerical columns in the DataFrame `df` using the `.describe()` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03c83191"
      },
      "source": [
        "display(df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa690272"
      },
      "source": [
        "**Checking unique Values**:\n",
        "To understand the distribution and potential inconsistencies in the categorical columns, I will check the unique values and their counts for 'Branch', 'City', 'Customer type', 'Gender', and 'Product line' using the `value_counts()` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e4c1b96"
      },
      "source": [
        "**Converting day and date column**:\n",
        "To prepare the data for time-series analysis, I need to convert the 'Date' column to datetime objects and then combine it with the 'Time' column to create a comprehensive 'Timestamp' column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62e7ecf9"
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Timestamp'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str))\n",
        "print(\"Converted 'Date' to datetime and created 'Timestamp' column.\")\n",
        "display(df[['Date', 'Time', 'Timestamp']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6740b72"
      },
      "source": [
        "sales_over_time = df.groupby('Timestamp')['Total'].sum()\n",
        "print(\"Total sales calculated over time:\")\n",
        "display(sales_over_time.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62336889"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x=sales_over_time.index, y=sales_over_time.values, label='Total Sales')\n",
        "plt.title('Total Sales Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad31d26f"
      },
      "source": [
        "**ANALYSING SALES BY PRODUCT LINE**:\n",
        "To analyze total sales by product line, I will group the DataFrame by 'Product line' and sum the 'Total' sales. Then, I will create a bar plot to visualize these sales, ensuring it includes a title, axis labels, and a legend for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a87e23b"
      },
      "source": [
        "sales_by_product_line = df.groupby('Product line')['Total'].sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=sales_by_product_line.index, y=sales_by_product_line.values, palette='viridis')\n",
        "plt.title('Total Sales by Product Line')\n",
        "plt.xlabel('Product Line')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total sales by product line calculated and visualized.\")\n",
        "display(sales_by_product_line.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f8f20e6"
      },
      "source": [
        "sales_by_city = df.groupby('City')['Total'].sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=sales_by_city.index, y=sales_by_city.values, palette='plasma')\n",
        "plt.title('Total Sales by City')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total sales by city calculated and visualized.\")\n",
        "display(sales_by_city.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d16a1177"
      },
      "source": [
        "**TOTAL SALES BY CUSTOMER **:\n",
        "To understand the sales contribution of different customer segments, I will group the DataFrame by 'Customer type', sum the 'Total' sales, and then visualize these aggregated sales using a bar plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a78ebd2a"
      },
      "source": [
        "sales_by_customer_type = df.groupby('Customer type')['Total'].sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=sales_by_customer_type.index, y=sales_by_customer_type.values, palette='coolwarm')\n",
        "plt.title('Total Sales by Customer Type')\n",
        "plt.xlabel('Customer Type')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total sales by customer type calculated and visualized.\")\n",
        "display(sales_by_customer_type.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e41feef"
      },
      "source": [
        "sales_by_gender = df.groupby('Gender')['Total'].sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=sales_by_gender.index, y=sales_by_gender.values, palette='coolwarm')\n",
        "plt.title('Total Sales by Gender')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total sales by gender calculated and visualized.\")\n",
        "display(sales_by_gender.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08d0571d"
      },
      "source": [
        "sales_by_payment = df.groupby('Payment')['Total'].sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=sales_by_payment.index, y=sales_by_payment.values, hue=sales_by_payment.index, palette='viridis', legend=False)\n",
        "plt.title('Total Sales by Payment Method')\n",
        "plt.xlabel('Payment Method')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total sales by payment method calculated and visualized.\")\n",
        "display(sales_by_payment.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "331b3295"
      },
      "source": [
        "df['Date_only'] = df['Timestamp'].dt.date\n",
        "sales_by_city_over_time = df.groupby(['Date_only', 'City'])['Total'].sum().reset_index()\n",
        "print(\"Aggregated sales by city and date:\")\n",
        "display(sales_by_city_over_time.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be17ddbb"
      },
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.lineplot(data=sales_by_city_over_time, x='Date_only', y='Total', hue='City', marker='o')\n",
        "plt.title('Total Sales Trends by City Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.legend(title='City')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualized total sales trends by city over time.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4fa20d0"
      },
      "source": [
        "sales_by_city_product = df.groupby(['City', 'Product line'])['Total'].sum().reset_index()\n",
        "print(\"Aggregated sales by city and product line:\")\n",
        "display(sales_by_city_product.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca6eb2e0"
      },
      "source": [
        "unique_cities = sales_by_city_product['City'].unique()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, city in enumerate(unique_cities):\n",
        "    plt.subplot(2, 2, i + 1) # Adjust subplot grid as needed\n",
        "    city_data = sales_by_city_product[sales_by_city_product['City'] == city].sort_values(by='Total', ascending=False)\n",
        "    sns.barplot(x='Product line', y='Total', data=city_data, palette='viridis')\n",
        "    plt.title(f'Total Sales by Product Line in {city}')\n",
        "    plt.xlabel('Product Line')\n",
        "    plt.ylabel('Total Sales')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualized top products by region.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357af14a"
      },
      "source": [
        "unique_cities = sales_by_city_product['City'].unique()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, city in enumerate(unique_cities):\n",
        "    plt.subplot(2, 2, i + 1) # Adjust subplot grid as needed\n",
        "    city_data = sales_by_city_product[sales_by_city_product['City'] == city].sort_values(by='Total', ascending=False)\n",
        "    sns.barplot(x='Product line', y='Total', data=city_data, hue='Product line', palette='viridis', legend=False)\n",
        "    plt.title(f'Total Sales by Product Line in {city}')\n",
        "    plt.xlabel('Product Line')\n",
        "    plt.ylabel('Total Sales')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualized top products by region.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90b1b54f"
      },
      "source": [
        "sales_per_transaction = df.groupby(['City', 'Invoice ID'])['Total'].sum().reset_index()\n",
        "average_basket_size_per_city = sales_per_transaction.groupby('City')['Total'].mean().sort_values(ascending=False)\n",
        "\n",
        "print(\"Average basket size per city calculated:\")\n",
        "display(average_basket_size_per_city.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94bb94ad"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=average_basket_size_per_city.index, y=average_basket_size_per_city.values, hue=average_basket_size_per_city.index, palette='viridis', legend=False)\n",
        "plt.title('Average Basket Size per City')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Average Basket Size')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualized average basket size per city.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "494fe182"
      },
      "source": [
        "df['Month'] = df['Timestamp'].dt.month\n",
        "print(\"Extracted 'Month' from 'Timestamp' column.\")\n",
        "display(df[['Timestamp', 'Month']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5adc6da1"
      },
      "source": [
        "sales_by_month = df.groupby('Month')['Total'].sum().reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Month', y='Total', data=sales_by_month, hue='Month', palette='viridis', legend=False)\n",
        "plt.title('Total Sales by Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total sales by month calculated and visualized.\")\n",
        "display(sales_by_month.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8215ecb5"
      },
      "source": [
        "df['DayOfWeek'] = df['Timestamp'].dt.day_name()\n",
        "print(\"Extracted 'DayOfWeek' from 'Timestamp' column.\")\n",
        "display(df[['Timestamp', 'DayOfWeek']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63352f04"
      },
      "source": [
        "sales_by_dayofweek = df.groupby('DayOfWeek')['Total'].sum().reindex(\n",
        "    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        ").reset_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='DayOfWeek', y='Total', data=sales_by_dayofweek, hue='DayOfWeek', palette='viridis', legend=False)\n",
        "plt.title('Total Sales by Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total sales by day of week calculated and visualized.\")\n",
        "display(sales_by_dayofweek.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08f0e6ca"
      },
      "source": [
        "numerical_cols = df.select_dtypes(include=['number'])\n",
        "print(\"Identified numerical columns:\")\n",
        "display(numerical_cols.head())\n",
        "print(f\"Number of numerical columns: {len(numerical_cols.columns)}\")\n",
        "print(\"List of numerical column names:\")\n",
        "print(numerical_cols.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbd0f108"
      },
      "source": [
        "correlation_matrix = numerical_cols.corr(method='pearson')\n",
        "print(\"Calculated Pearson correlation matrix:\")\n",
        "display(correlation_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3babf32"
      },
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Pearson Correlation Matrix of Numerical Features')\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualized the correlation matrix as a heatmap.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12a0e79c"
      },
      "source": [
        "for column in numerical_cols.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(y=numerical_cols[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "    plt.ylabel('Value')\n",
        "    plt.grid(axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Generated box plots for all numerical columns.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cadcf8c"
      },
      "source": [
        "columns_to_check = ['Unit price', 'Quantity', 'Total']\n",
        "outliers_data = {}\n",
        "\n",
        "for column in columns_to_check:\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
        "\n",
        "    outliers_data[column] = {\n",
        "        'count': len(outliers),\n",
        "        'values': outliers.tolist() if not outliers.empty else []\n",
        "    }\n",
        "\n",
        "print(\"Outlier analysis using IQR:\")\n",
        "for column, data in outliers_data.items():\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"  Number of outliers: {data['count']}\")\n",
        "    if data['count'] > 0:\n",
        "        print(f\"  Outlier values (first 10 if many): {data['values'][:10]}\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of Key Findings\n",
        "Sales Performance Overview\n",
        "\n",
        "Overall Sales Trends: Daily sales showed noticeable fluctuations across the January–March period, with no sustained upward or downward trend, indicating relatively stable overall performance.\n",
        "\n",
        "Seasonality: January recorded the highest total sales, followed by March, while February experienced the lowest. On a weekly basis, Tuesdays and Saturdays consistently showed stronger sales, whereas Mondays underperformed.\n",
        "\n",
        "Product & Customer Insights\n",
        "\n",
        "Product Line Performance:\n",
        "Food and beverages emerged as the top-performing category overall, followed by Sports and travel and Electronic accessories. Health and beauty generated the lowest total sales.\n",
        "\n",
        "Customer Type: Sales contributions from Members and Normal customers were almost evenly split, with members contributing marginally higher revenue.\n",
        "\n",
        "Gender: Female customers generated slightly higher total sales than male customers, although the difference was minimal.\n",
        "\n",
        "Regional & City-Level Insights\n",
        "\n",
        "City-wise Sales: Sales were relatively balanced across the three cities, with Naypyitaw recording slightly higher total sales than Yangon and Mandalay.\n",
        "\n",
        "Regional Sales Patterns: All cities followed similar daily sales fluctuation patterns, suggesting shared external or seasonal drivers.\n",
        "\n",
        "Top Product Lines by City:\n",
        "\n",
        "Mandalay: Sports and travel, Health and beauty\n",
        "\n",
        "Naypyitaw: Food and beverages, Fashion accessories\n",
        "\n",
        "Yangon: Home and lifestyle, Sports and travel\n",
        "\n",
        "Average Basket Size: Naypyitaw recorded the highest average basket value ($337.10), followed by Mandalay ($319.87) and Yangon ($312.35).\n",
        "\n",
        "Payment Behaviour\n",
        "\n",
        "Payment Methods: Cash was the most used payment method ($112,206.57), closely followed by Ewallet ($109,993.11). Credit cards contributed the lowest sales ($100,767.07), indicating a preference for cash and digital wallets.\n",
        "\n",
        "Business Insights & Recommendations\n",
        "\n",
        "Target High-Impact Periods: Leverage peak sales days (Tuesdays and Saturdays) and high-performing months (January) for targeted promotions, optimized staffing, and inventory planning.\n",
        "\n",
        "Category Optimisation: Continue investing in Food and beverages as a core revenue driver. For Health and beauty, explore targeted marketing, bundling, or product mix optimisation to improve performance.\n",
        "\n",
        "Regional Strategy: Align product assortment and marketing campaigns with city-specific preferences to maximise regional performance.\n",
        "\n",
        "Payment Strategy: Promote digital wallet incentives to further shift customers toward faster, more efficient payment methods.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "✅ Project Conclusion\n",
        "\n",
        "This analysis explored retail sales performance across multiple dimensions, including time, product lines, customer demographics, payment methods, and regional trends. The findings indicate that while overall sales remained relatively stable over the three-month period, clear patterns emerged in product preferences, city-level performance, and customer purchasing behaviour.\n",
        "\n",
        "Food and beverages consistently drove the highest revenue, highlighting its importance as a core category, while variations in top-selling product lines across cities emphasised the value of region-specific strategies. Seasonal and daily trends revealed opportunities to optimise promotions, staffing, and inventory during peak periods such as January, Tuesdays, and Saturdays. Additionally, the dominance of cash and e-wallet payments suggests customer preference for quick and accessible transaction methods.\n",
        "\n",
        "Overall, this project demonstrates how exploratory data analysis and visualisation can uncover actionable business insights. The approach and findings can support data-driven decision-making in sales optimisation, marketing strategy, and operational planning within a retail environment.\n",
        "\n",
        "\n",
        "Skills Demonstrated\n",
        "\n",
        "Data Analysis & Exploration: Conducted exploratory data analysis (EDA) to identify sales trends, patterns, and anomalies across time, regions, and product lines.\n",
        "\n",
        "Python Programming: Utilised Python libraries such as Pandas, NumPy, Matplotlib, and Seaborn to clean, analyse, and visualise data.\n",
        "\n",
        "Data Visualisation: Created meaningful visualisations including time-series plots, bar charts, heatmaps, and regional comparisons to support insights.\n",
        "\n",
        "Business Insight Generation: Translated analytical findings into actionable recommendations related to sales optimisation, marketing strategy, and regional performance.\n",
        "\n",
        "Statistical Thinking: Applied descriptive statistics to understand distributions, customer behaviour, and average basket size across regions.\n",
        "\n",
        "Communication & Storytelling: Presented insights in a clear, structured, and business-focused manner suitable for both technical and non-technical stakeholders.\n",
        "\n",
        "\n",
        "“This project demonstrates my ability to analyse retail sales data end-to-end using Python, uncover key trends across products, customers, and regions, and translate those findings into actionable business recommendations.”\n"
      ],
      "metadata": {
        "id": "xRhrL6F9l3Ld"
      }
    }
  ]
}